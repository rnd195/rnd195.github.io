[
  {
    "objectID": "privacy.html",
    "href": "privacy.html",
    "title": "Privacy policy",
    "section": "",
    "text": "I (Martin Řanda or rnd195) do not collect any personal data from visitors of this website.\nThis website is hosted using GitHub Pages. Please note that the host may collect personal data as described in the documentation for GitHub Pages:\n\nWhen a GitHub Pages site is visited, the visitor’s IP address is logged and stored for security purposes, regardless of whether the visitor has signed into GitHub or not. For more information about GitHub’s security practices, see GitHub Privacy Statement.\n\nThis website may contain links to third-party websites. Please note that once you leave this site and access these external websites, this privacy policy no longer applies.\nI may update this privacy policy from time to time. Any changes will be posted on this page with a revised effective date. If you have any questions or concerns regarding this privacy policy, please contact me at contact@rnd195.anonaddy.com.\nLast updated: 1 Jan 2025"
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "Text, images, code, or other resources that I (Martin Řanda or rnd195) produced and posted on my blog are licensed under CC BY 4.0 unless stated otherwise.\nThe code that I produced to create this website is licensed under the MIT license.\nThe Inter font used on this website is made by the Inter Project Authors and is licensed under the SIL Open Font License 1.1.\nThe tool used to generate this website, Quarto, is licensed under the MIT license.\n\nAll relevant license files can be also found within the GitHub repository of this website in the licenses folder."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Blog",
    "section": "",
    "text": "Benchmarking TimesFM on electricity consumption data\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 26, 2025\n\n\nMartin Řanda\n\n\n\n\n\n\nNo matching items\n\n\nOpinions expressed on my blog are my own."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Martin Řanda",
    "section": "",
    "text": "Hi, I’m Martin Řanda.\nI work on forecasting models, data processing, and interactive visualizations in a major Czech energy trading company based in Prague. I have a Master’s degree in Financial Markets and Data Analysis from Charles University.\nThis is what I have been up to recently:\n\n\n\n\n\nDate\n\n\nTitle\n\n\n\n\n\n\nJan 26, 2025\n\n\nBenchmarking TimesFM on electricity consumption data\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/tfm-electricity-consumption/index.html",
    "href": "posts/tfm-electricity-consumption/index.html",
    "title": "Benchmarking TimesFM on electricity consumption data",
    "section": "",
    "text": "Generating forecasts of Finnish electricity consumption using the TimesFM 200M model by Google Research\nIn early 2024, Google Research announced TimesFM, a pre-trained univariate time-series foundation model for time-series forecasting.1 First, let me break down the terminology. The general idea is that this is a model for sequences of data that are ordered in time (time-series). A few examples of time-series include: annual inflation rate, monthly precipitation, weekly water demand, or hourly temperatures. This being a forecasting model simply means that we are interested in predicting the future. Univariate implies that this model only takes in and outputs a single time-series—in other words, no other variables are utilized. Pre-trained means, for our purposes, that we don’t need to run the complex process of training the model. We simply download a large file that contains all the 200M parameters for the model to produce forecasts. Finally, a foundation model is one that has been pre-trained on a large number of diverse datasets.2\nTo be honest, when I first read about this model, I realized that I have never used a pre-trained time-series model. And it’s not like these didn’t exist before. In fact, several pre-trained foundation models have been released (see, for example3). But seeing Google Research announce their pre-trained time-series forecasting model put this whole category of models on my radar.\nIn their paper on TimesFM,4 the authors tested the model’s performance on popular time-series datasets and demonstrated that TimesFM was, in the majority of cases, able to outperform both classical and deep learning models using their methodology. For this reason, I was interested in knowing how well it would forecast something I am familiar with—electricity consumption."
  },
  {
    "objectID": "posts/tfm-electricity-consumption/index.html#data",
    "href": "posts/tfm-electricity-consumption/index.html#data",
    "title": "Benchmarking TimesFM on electricity consumption data",
    "section": "Data",
    "text": "Data\nSpecifically, I decided to use electricity consumption data from the operator of the Finnish grid through their Open Data portal.5 At this point, I believe that it is important to give my words of appreciation to the people at Fingrid for providing easy access to the data with clear license terms. In my view, this is the way open data should be done, so thank you!\nFrom my experience, electricity consumption in (most of?) Europe typically follows these three major seasonal patterns:\n\n\n\n\n\n\nFigure 1: Simplified electricity consumption pattern in (most of?) Europe\n\n\n\nFirstly, there’s typically high electricity consumption in winter, lowering in spring, low during summer months, and slowly climbing upward in autumn. Note that the dip at the end of the year is due to winter holidays and it can be quite substantial. Secondly, on a typical work week, the Monday to Friday pattern looks fairly similar, but there is lower electricity consumption during the weekend. Finally, if we look at a single day’s worth of electricity consumption data, there will likely be less electricity consumed at night and consumption will peak around midday, perhaps in the afternoon, or early evening.\nIf we look at hourly electricity consumption in Finland (resampled from 15-min by averaging), I can cherry-pick specific weeks or days to make the series look similar to the patterns illustrated above. However, the full 2024 snapshot makes it clear that electricity consumption patterns in Finland are more nuanced.\n\n\n\n\n\n\nFigure 2: Hourly electricity consumption in Finland (MWh), 2024"
  },
  {
    "objectID": "posts/tfm-electricity-consumption/index.html#setup",
    "href": "posts/tfm-electricity-consumption/index.html#setup",
    "title": "Benchmarking TimesFM on electricity consumption data",
    "section": "Setup",
    "text": "Setup\nI will be benchmarking the 200M parameter model on the whole 2024 hourly consumption data illustrated above. Naturally, we already know what the 2024 electricity consumption looks like, but it would be highly impractical to produce forecasts from the current point in time onward while waiting for the future to materialize to collect the data and determine the accuracy of our predictions. Instead, we can go step by step, limiting the knowledge our forecasting model takes in, generate forecasts at that point in time, and immediately compare against the actual values. This is called pseudo-out-of-sample forecasting (see, for example6).\nIn electricity consumption forecasting, it often makes sense to think about the data in full days, not just individual hours. Therefore, I will be forecasting up to 24 hours ahead following the scheme described below:\n\nStart on Jan 1st 2024, 00:00 – this will be the first prediction\nWith no knowledge of electricity consumption on Jan 1st, produce forecasts up to 23:00 (included)\nSave these forecasts and move by one day\nGenerate predictions for Jan 2nd (00:00, 01:00, …, 23:00)\nMove by one day\nContinue until you reach Dec 31st 2024\n\nBelow is an illustration of the scheme—the three vertical lines are the starting points for each 24-hour prediction as well as a knowledge-cutoff line. The dashed curves illustrate predictions while the solid line is meant to represent actual values that are not “seen” by the model beforehand.\n\n\n\n\n\n\nFigure 3: Forecasting scheme illustration\n\n\n\nTo produce the forecasts, I am using the official timesfm Python package and the package-specific code only really takes a few lines if we leave all other hyperparameters set to their default values.\n# Up to 24 hours ahead\nhorizon = 24\n# Define model parameters\nmodel_params = timesfm.TimesFmHparams(\n    backend=\"gpu\",\n    horizon_len=horizon\n)\n# Load checkpoint from huggingface\nhf_checkpoint = timesfm.TimesFmCheckpoint(\n    huggingface_repo_id=\"google/timesfm-1.0-200m-pytorch\"\n)\n# Setup the model\nmodel = timesfm.TimesFm(\n    hparams=model_params,\n    checkpoint=hf_checkpoint\n)\nAssuming that our data is stored in a pandas DataFrame, we can produce forecasts by running\nfcst = model.forecast_on_df(\n    # Formatted dataframe\n    inputs=df,\n    # Data frequency (hourly)\n    freq=\"h\",\n    # Target variable column name\n    value_name=\"consumption\",\n    # -1 sets the number of processes to cpu count\n    num_jobs=-1\n)\nAnd that’s about it. You may find the whole implementation in a Jupyter notebook linked in the floating table of contents on the right (or here)."
  },
  {
    "objectID": "posts/tfm-electricity-consumption/index.html#results",
    "href": "posts/tfm-electricity-consumption/index.html#results",
    "title": "Benchmarking TimesFM on electricity consumption data",
    "section": "Results",
    "text": "Results\nFirstly, let me briefly summarize the setup and all the parameters used to generate the forecasts:\n\nData\n\nelectricity consumption in Finland in MWh\nhourly frequency (resampled from 15-min by averaging)\nstart 2024-01-01 00:00, end 2024-12-31 23:00 (excluding some missing values)\n\nForecasting scheme\n\nup to 24 hours ahead\nstart at 00:00, generate predictions up to 23:00 each day, and move to the next day\n\nModel\n\nTimesFM 200M with default parameters\n\n\n\nPlots\nFor visual convenience, I connected all the forecasts into a single series. However, let me once again note that the predictions were generated for each day separately (denoted by the vertical gridlines).\nWith that in mind, let’s take a look at some of the forecasts (in red) versus actual values (in blue), starting in the first week of Jan 2024:\n\n\n\n\n\n\nFigure 4: Forecasts vs actual values (first week of Jan 2024)\n\n\n\nMy first thoughts are that the model is somewhat capable of capturing the general day/night pattern as well as the rough daily consumption level (with some exceptions). However, it seems to struggle with the shape of the peak hours (midday/afternoon) for most days of the week. Of course, this is just a single week out of the whole year, but these symptoms appear to be prevalent in most weeks of the year as suggested by the monthly error metrics displayed later (Figure 7 and Figure 8).\nBelow is a snapshot of early July 2024 forecasts:\n\n\n\n\n\n\nFigure 5: Forecasts vs actual values (first week of Jul 2024)\n\n\n\nThis is a totally different story as it seems that the model was capable of generating relatively accurate forecasts. This can likely be attributed to the less volatile pattern of electricity consumption in the summer months of 2024 which is certainly helpful for univariate models.\nFinally, let’s take a look at a sample from October 2024:\n\n\n\n\n\n\nFigure 6: Forecasts vs actual values (first week of Oct 2024)\n\n\n\nIn this case, we get similar issues with the shape and sometimes even the level as in the first displayed plot. Interestingly, perhaps due to the autoregressive nature of the model, it was able to capture the distinct “U” shape of the peak consumption.\n\n\nError metrics\nUsing the forecasting scheme outlined above, the 200M TimesFM model with default parameters was capable of recording the following accuracy metrics on the 2024 Finnish electricity consumption data\n\n\n\n\n\n\n\n\nMetric (total)\nValue\nExplainer\n\n\n\n\nMean absolute percentage error (MAPE)\n2.659%\nOn average, how much does a single point forecast deviate from actual values in absolute terms. Denoted in %\n\n\nRoot mean square error (RMSE)\n356.89071 MWh\nOn average, how much does a single point forecast deviate from actual values in squared terms. Larger mistakes are penalized more. Denoted in MWh\n\n\nR-squared\n95.817%\nThis can help determine shape accuracy, but not level\n\n\nMean bias error\n18.25352 MWh\nOverestimation (+) or underestimation (-), on average\n\n\n\nLet’s also take a look at MAPE and RMSE grouped by month to get a better picture of which months were easier to forecast with the model.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Monthly MAPE\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Monthly RMSE\n\n\n\n\n\n\nIt is clear that the 200M TimesFM model was the most accurate in July and August which can partly be seen in Figure 5 as discussed earlier. In terms of RMSE, the least accurate forecasts were generated in the first month of 2024."
  },
  {
    "objectID": "posts/tfm-electricity-consumption/index.html#thoughts",
    "href": "posts/tfm-electricity-consumption/index.html#thoughts",
    "title": "Benchmarking TimesFM on electricity consumption data",
    "section": "Thoughts",
    "text": "Thoughts\nWhile I cannot confidently comment on the relative levels of these error metrics with respect to Finnish data due to a lack of experience with Finnish electricity consumption, I find these results impressive for a univariate model that doesn’t need to be trained. It is without a doubt that multivariate models would outperform this framework in this particular forecasting exercise. Still, I think it is valuable to benchmark the model on data that is known to be forecastable as it may help us understand what we can expect from the framework in other domains.\nRegardless, I am now very interested in future foundation time-series models that Google Research may release. Perhaps this is a sign of what’s to come in the time-series forecasting domain? I hope so. On that note, the TimesFM repository on GitHub has recently been updated with a 500M variant. Would this model generate more accurate forecasts in the exercise outlined in this post? It’s possible but that is a question for another time.\nComment on GitHub Notebook with code"
  },
  {
    "objectID": "posts/tfm-electricity-consumption/index.html#footnotes",
    "href": "posts/tfm-electricity-consumption/index.html#footnotes",
    "title": "Benchmarking TimesFM on electricity consumption data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nGoogle Research (2024). A decoder-only foundation model for time-series forecasting. https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/↩︎\nSee, for example https://www.ibm.com/think/topics/foundation-models↩︎\nFor instance https://github.com/qianlima-lab/time-series-ptms?tab=readme-ov-file#pre-trained-models-on-time-series-forecasting↩︎\nDas, A., Kong, W., Sen, R., & Zhou, Y. (2023). A decoder-only foundation model for time-series forecasting. arXiv preprint arXiv:2310.10688. https://arxiv.org/abs/2310.10688↩︎\n“Electricity consumption in Finland” provided by Fingrid is licensed under CC BY 4.0↩︎\nHanck, C., Arnold, M., Gerber, A., & Schmelzer, M. (2024). Introduction to Econometrics with R. https://www.econometrics-with-r.org/14.8-niib.html#pseudo-out-of-sample-forecasting↩︎"
  }
]